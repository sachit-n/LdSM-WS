{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import codecs\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from xclib.data import data_utils #https://github.com/kunaldahiya/pyxclib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/Users/sachitnagpal/Library/Mobile Documents/com~apple~CloudDocs/nyu/thesis/code/LdSM-WS/preprocess_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exc_labels = data_utils.read_sparse_file(\"thesis/code/swiftxml/Tree_Extreme_Classifiers/Sandbox/Results/EUR-Lex/exc_tst_X_Y.txt\").toarray()\n",
    "# inc_labels = data_utils.read_sparse_file(\"thesis/code/swiftxml/Tree_Extreme_Classifiers/Sandbox/Results/EUR-Lex/inc_tst_X_Y.txt\").toarray()\n",
    "# labels = data_utils.read_sparse_file(\"/Users/sachitnagpal/Library/Mobile Documents/com~apple~CloudDocs/nyu/thesis/code/swiftxml/Tree_Extreme_Classifiers/Sandbox/Data/EUR-Lex/tst_X_Y.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_path = \"raw_data/AmazonCat-13K.bow\"\n",
    "\n",
    "dataset = \"amazonCat13\"\n",
    "data_path = f\"data/{dataset}/\"\n",
    "warm_start_data_path = f\"warm_start_data/{dataset}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_features, tr_labels, _, _, _ = data_utils.read_data(f'{raw_data_path}/train.txt')\n",
    "te_features, te_labels, _, _, _ = data_utils.read_data(f'{raw_data_path}/test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1186239\n",
      "306782\n"
     ]
    }
   ],
   "source": [
    "print(tr_features.shape[0])\n",
    "print(te_features.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_filter_ixs = np.array((tr_labels.sum(axis=1)>0)&(tr_features.sum(axis=1)>0)).flatten()\n",
    "tr_features = tr_features[tr_filter_ixs, :]\n",
    "tr_labels = tr_labels[tr_filter_ixs, :]\n",
    "\n",
    "te_filter_ixs = np.array((te_labels.sum(axis=1)>0)&(te_features.sum(axis=1)>0)).flatten()\n",
    "te_features = te_features[te_filter_ixs, :]\n",
    "te_labels = te_labels[te_filter_ixs, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14838"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array((te_labels.sum(axis=1)<=1)).flatten().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1186239\n",
      "306782\n"
     ]
    }
   ],
   "source": [
    "print(len(tr_filter_ixs))\n",
    "print(len(te_filter_ixs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_utils.write_data(f\"{data_path}/train.txt\", tr_features, tr_labels)\n",
    "# data_utils.write_data(f\"{data_path}/test.txt\", te_features, te_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_utils.write_sparse_file(tr_features, \"data/amazonCat13/train_X.txt\")\n",
    "# data_utils.write_sparse_file(tr_labels, \"data/amazonCat13/train_Y.txt\")\n",
    "\n",
    "# data_utils.write_sparse_file(te_features, \"data/amazonCat13/test_X.txt\")\n",
    "# data_utils.write_sparse_file(te_labels, \"data/amazonCat13/test_Y.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verifying for 20\n",
      "if rev_labels is 1 at a position in matrix, labels is certainly 1 at this loc\n",
      "avg. num labels per point is 5.103092670440674\n",
      "avg. num revealed labels per point is 0.585487425327301\n",
      "avg. num hidden labels per point is 4.517605304718018\n",
      "at least 1 label is hidden for each example\n",
      "verifying for 40\n",
      "if rev_labels is 1 at a position in matrix, labels is certainly 1 at this loc\n",
      "avg. num labels per point is 5.103092670440674\n",
      "avg. num revealed labels per point is 1.614302635192871\n",
      "avg. num hidden labels per point is 3.4887900352478027\n",
      "at least 1 label is hidden for each example\n",
      "verifying for 60\n",
      "if rev_labels is 1 at a position in matrix, labels is certainly 1 at this loc\n",
      "avg. num labels per point is 5.103092670440674\n",
      "avg. num revealed labels per point is 2.6793880462646484\n",
      "avg. num hidden labels per point is 2.4237048625946045\n",
      "at least 1 label is hidden for each example\n",
      "verifying for 80\n",
      "if rev_labels is 1 at a position in matrix, labels is certainly 1 at this loc\n",
      "avg. num labels per point is 5.103092670440674\n",
      "avg. num revealed labels per point is 3.7082033157348633\n",
      "avg. num hidden labels per point is 1.3948894739151\n",
      "at least 1 label is hidden for each example\n"
     ]
    }
   ],
   "source": [
    "def verify_warm_start_data(labels, rev_labels):\n",
    "    assert labels.max()==1\n",
    "    assert labels.min()==0\n",
    "    assert rev_labels.max()==1\n",
    "    assert rev_labels.min()==0\n",
    "    \n",
    "    unk_labels = labels - rev_labels\n",
    "    assert unk_labels.min()==0 #if rev_labels is 1 at a loc, labels is certainly 1   \n",
    "    print(\"if rev_labels is 1 at a position in matrix, labels is certainly 1 at this loc\")\n",
    "    \n",
    "    print(f\"avg. num labels per point is {labels.sum(axis=1).mean()}\")\n",
    "    print(f\"avg. num revealed labels per point is {rev_labels.sum(axis=1).mean()}\")\n",
    "    print(f\"avg. num hidden labels per point is {unk_labels.sum(axis=1).mean()}\")\n",
    "    \n",
    "#     assert unk_labels.sum(axis=1)==0\n",
    "    no_rel_label_ixs = np.argwhere(labels.sum(axis=1)==0)\n",
    "    no_hidden_label_ixs = np.argwhere(labels.sum(axis=1)==0)\n",
    "    np.testing.assert_almost_equal(no_rel_label_ixs, no_hidden_label_ixs)\n",
    "    print(\"at least 1 label is hidden for each example\")\n",
    "    \n",
    "    expected = unk_labels+rev_labels\n",
    "    is_equal = (expected!=labels).nnz==0\n",
    "    assert is_equal\n",
    "#     np.testing.assert_almost_equal(expected.toarray(), labels.toarray())\n",
    "    \n",
    "\n",
    "# te_labels = data_utils.read_sparse_file(\"results/amazonCat13/test_Y.txt\")\n",
    "fracs = [20,40,60,80]\n",
    "for frac in fracs:\n",
    "    rev_labels = data_utils.read_sparse_file(f\"{warm_start_data_path}/inc_test_Y_{frac}.txt\")\n",
    "    print(f\"verifying for {frac}\")\n",
    "    verify_warm_start_data(te_labels, rev_labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_nf = []\n",
    "def format_label_embeddings(embeddings, label_tags_file):\n",
    "\n",
    "    with open(label_tags_file, 'r', encoding='latin1') as f:\n",
    "        temp = f.readlines()\n",
    "    dataset_vocab = [item.rstrip(\"\\n\") for item in temp] #list of all words in given dataset\n",
    "    del temp\n",
    "#     dataset_vocab = dataset_vocab[:10000] #For Sample Toy\n",
    "    print(len(dataset_vocab))\n",
    "\n",
    "    label_embeddings = np.zeros((len(dataset_vocab), embeddings.vector_size))\n",
    "    not_found_count = 0\n",
    "\n",
    "    for i in range(len(dataset_vocab)):\n",
    "        label_embeddings[i, :] = np.zeros(embeddings.vector_size)\n",
    "        words = re.split(\" |_|-\", dataset_vocab[i])\n",
    "        for word in words:\n",
    "            try:\n",
    "                label_embeddings[i, :] += embeddings[word]\n",
    "            except KeyError:\n",
    "                label_embeddings[i, :] += np.random.randn(embeddings.vector_size, )*0.01\n",
    "                not_found_count+=1\n",
    "                labels_nf.append(dataset_vocab[i])\n",
    "    print(\"#Words with no word embeddings\", not_found_count)\n",
    "    return label_embeddings\n",
    "\n",
    "def find(array, neq_val=None):\n",
    "    \"\"\"\n",
    "    params:\n",
    "    array: 2D array\n",
    "    neq_val: 0 for user features, labels, and None for label/item features\n",
    "    \"\"\"\n",
    "    vals = array[array!=neq_val]\n",
    "    vals = np.array(vals).flatten()\n",
    "    indeces = np.argwhere(array!=neq_val)+1\n",
    "    indeces_ax0 = indeces[:, 0]\n",
    "    indeces_ax1 = indeces[:, 1]\n",
    "    \n",
    "    return vals, indeces_ax0, indeces_ax1, indeces\n",
    "    \n",
    "def format_data(frac, save_path):\n",
    "    tr_x = data_utils.read_sparse_file(f\"{warm_start_data_path}/train_X.txt\")\n",
    "    tr_y = data_utils.read_sparse_file(f\"{warm_start_data_path}/train_Y_{frac}.txt\")\n",
    "    te_x = data_utils.read_sparse_file(f\"{warm_start_data_path}/test_X.txt\")\n",
    "    inc_te_y = data_utils.read_sparse_file(f\"{warm_start_data_path}/inc_test_Y_{frac}.txt\")\n",
    "    exc_te_y = data_utils.read_sparse_file(f\"{warm_start_data_path}/exc_test_Y_{frac}.txt\")\n",
    "    \n",
    "    tr_x_v, tr_x_ix, tr_x_col_ix, _ = find(tr_x, 0)\n",
    "    te_x_v, te_x_ix, te_x_col_ix, _ = find(te_x, 0)\n",
    "    \n",
    "    _, tr_y_ix, tr_y_col_ix, _ = find(tr_y, 0)\n",
    "    _, inc_te_y_ix, inc_te_y_col_ix, _ = find(inc_te_y, 0)\n",
    "    _, exc_te_y_ix, exc_te_y_col_ix, _ = find(exc_te_y, 0)\n",
    "    \n",
    "    \n",
    "    np.savetxt(os.path.join(save_path, f\"tr_x_v.csv\"), tr_x_v, delimiter=\"\\n\")\n",
    "    np.savetxt(os.path.join(save_path, f\"tr_x_ix.csv\"), tr_x_ix, delimiter=\"\\n\", fmt=\"%-d\")\n",
    "    np.savetxt(os.path.join(save_path, f\"tr_x_col_ix.csv\"), tr_x_col_ix, delimiter=\"\\n\", fmt=\"%-d\")\n",
    "    np.savetxt(os.path.join(save_path, f\"te_x_v.csv\"), te_x_v, delimiter=\"\\n\")\n",
    "    np.savetxt(os.path.join(save_path, f\"te_x_ix.csv\"), te_x_ix, delimiter=\"\\n\", fmt=\"%-d\")\n",
    "    np.savetxt(os.path.join(save_path, f\"te_x_col_ix.csv\"), te_x_col_ix, delimiter=\"\\n\", fmt=\"%-d\")\n",
    "    \n",
    "    np.savetxt(os.path.join(save_path, f\"tr_y_ix_{frac}.csv\"), tr_y_ix, delimiter=\"\\n\", fmt=\"%-d\")\n",
    "    np.savetxt(os.path.join(save_path, f\"tr_y_col_ix_{frac}.csv\"), tr_y_col_ix, delimiter=\"\\n\", fmt=\"%-d\")\n",
    "    np.savetxt(os.path.join(save_path, f\"inc_{frac}_te_y_ix.csv\"), inc_te_y_ix, delimiter=\"\\n\", fmt=\"%-d\")\n",
    "    np.savetxt(os.path.join(save_path, f\"inc_{frac}_te_y_col_ix.csv\"), inc_te_y_col_ix, delimiter=\"\\n\", fmt=\"%-d\")\n",
    "    np.savetxt(os.path.join(save_path, f\"exc_{frac}_te_y_ix.csv\"), exc_te_y_ix, delimiter=\"\\n\", fmt=\"%-d\")\n",
    "    np.savetxt(os.path.join(save_path, f\"exc_{frac}_te_y_col_ix.csv\"), exc_te_y_col_ix, delimiter=\"\\n\", fmt=\"%-d\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec500 = KeyedVectors.load_word2vec_format(\"../../word2vec/enwiki_20180420_500d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13330\n",
      "#Words with no word embeddings 2873\n"
     ]
    }
   ],
   "source": [
    "label_features = format_label_embeddings(word2vec500, f'{raw_data_path}/Yf.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13330, 500)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf = csr_matrix(label_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_utils.write_sparse_file(lf, \"amzCat13_lf.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a78b1fb2bab9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'raw_data/amaz.../Yf.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-769213044a01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mformat_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarm_start_data_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlabel_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat_label_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2vec500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{raw_data_path}/Yf.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mlf_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlf_ix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlf_col_ix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-ab0526e5e705>\u001b[0m in \u001b[0;36mformat_label_embeddings\u001b[0;34m(embeddings, label_tags_file)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mformat_label_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_tags_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_tags_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdataset_vocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#list of all words in given dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'raw_data/amaz.../Yf.txt'"
     ]
    }
   ],
   "source": [
    "fracs = [20,40,60,80]\n",
    "for frac in fracs:\n",
    "    format_data(frac, warm_start_data_path)\n",
    "\n",
    "label_features = format_label_embeddings(word2vec500, f'{raw_data_path}/Yf.txt')\n",
    "\n",
    "lf_v, lf_ix, lf_col_ix, _ = find(label_features, None)\n",
    "\n",
    "np.savetxt(os.path.join(warm_start_data_path, f\"w2v_emb_v.csv\"), lf_v, delimiter=\"\\n\")\n",
    "np.savetxt(os.path.join(warm_start_data_path, f\"w2v_emb_ix.csv\"), lf_ix, delimiter=\"\\n\", fmt=\"%-d\")\n",
    "np.savetxt(os.path.join(warm_start_data_path, f\"w2v_emb_col_ix.csv\"), lf_col_ix, delimiter=\"\\n\", fmt=\"%-d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_x = data_utils.read_sparse_file(f\"{warm_start_data_path}/train_X.txt\")\n",
    "tr_y = data_utils.read_sparse_file(f\"{warm_start_data_path}/train_Y_{frac}.txt\")\n",
    "te_x = data_utils.read_sparse_file(f\"{warm_start_data_path}/test_X.txt\")\n",
    "inc_te_y = data_utils.read_sparse_file(f\"{warm_start_data_path}/inc_test_Y_{frac}.txt\")\n",
    "exc_te_y = data_utils.read_sparse_file(f\"{warm_start_data_path}/exc_test_Y_{frac}.txt\")\n",
    "# label_features = format_label_embeddings(word2vec500, f'{raw_data_path}/Yf.txt')\n",
    "\n",
    "tr_x_v, tr_x_ix, tr_x_col_ix, _ = find(tr_x, 0)\n",
    "te_x_v, te_x_ix, te_x_col_ix, _ = find(te_x, 0)\n",
    "\n",
    "_, tr_y_ix, tr_y_col_ix, _ = find(tr_y, 0)\n",
    "_, inc_te_y_ix, inc_te_y_col_ix, _ = find(inc_te_y, 0)\n",
    "_, exc_te_y_ix, exc_te_y_col_ix, _ = find(exc_te_y, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20762, 101938)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20762, 30938)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6616, 101938)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6616, 30938)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inc_te_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6616, 30938)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exc_te_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13890789,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_x_v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13890789,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_x_ix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13890789,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_x_col_ix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4364217,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te_x_v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4364217,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te_x_ix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4364217,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te_x_col_ix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(286242,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_y_ix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(286242,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_y_col_ix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22537,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inc_te_y_ix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22537,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inc_te_y_col_ix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103335,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exc_te_y_ix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103335,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exc_te_y_col_ix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  3,  5, 10, 10, 10, 12, 12, 14, 15], dtype=int32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inc_te_y_ix[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = np.loadtxt(\"warm_start_data/amazonCat13/tr_y_ix_20.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6159056,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(f\"exc_{frac}_te_y_ix.csv\", exc_te_y_ix, delimiter=\"\\n\", fmt=\"%-d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "check2 = np.loadtxt(\"exc_80_te_y_ix.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(427927,)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
