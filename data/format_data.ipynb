{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sn2811/.local/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import codecs\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from xclib.data import data_utils #https://github.com/kunaldahiya/pyxclib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_nf = []\n",
    "def format_label_embeddings(embeddings, label_tags_file):\n",
    "\n",
    "    with open(label_tags_file, 'r', encoding='latin1') as f:\n",
    "        temp = f.readlines()\n",
    "    dataset_vocab = [item.rstrip(\"\\n\") for item in temp] #list of all words in given dataset\n",
    "    del temp\n",
    "#     dataset_vocab = dataset_vocab[:10000] #For Sample Toy\n",
    "    print(len(dataset_vocab))\n",
    "\n",
    "    label_embeddings = np.zeros((len(dataset_vocab), embeddings.vector_size))\n",
    "    not_found_count = 0\n",
    "\n",
    "    for i in range(len(dataset_vocab)):\n",
    "        label_embeddings[i, :] = np.zeros(embeddings.vector_size)\n",
    "        words = re.split(\" |_|-\", dataset_vocab[i])\n",
    "        for word in words:\n",
    "            try:\n",
    "                label_embeddings[i, :] += embeddings[word]\n",
    "            except KeyError:\n",
    "                label_embeddings[i, :] += np.random.randn(embeddings.vector_size, )*0.01\n",
    "                not_found_count+=1\n",
    "                labels_nf.append(dataset_vocab[i])\n",
    "    print(\"#Words with no word embeddings\", not_found_count)\n",
    "    return label_embeddings\n",
    "\n",
    "def find(array, neq_val=None, filter_ixs=None):\n",
    "    \"\"\"\n",
    "    params:\n",
    "    array: 2D array\n",
    "    neq_val: 0 for user features, labels, and None for label/item features\n",
    "    \"\"\"\n",
    "    vals = array[array!=neq_val]\n",
    "    vals = np.array(vals).flatten()\n",
    "    indeces = np.argwhere(array!=neq_val)+1\n",
    "    indeces_ax0 = indeces[:, 0]\n",
    "    indeces_ax1 = indeces[:, 1]\n",
    "    \n",
    "    return vals, indeces_ax0, indeces_ax1, indeces\n",
    "\n",
    "def save_labels(tr_points, tr_dims, te_points, te_dims, save_path, save_name, reveal_percent=\"\"):\n",
    "    np.savetxt(os.path.join(save_path, f\"{save_name}_trLabelPoint{reveal_percent}.csv\"), tr_points, delimiter=\"\\n\", fmt=\"%-d\")\n",
    "    np.savetxt(os.path.join(save_path, f\"{save_name}_trLabelDim{reveal_percent}.csv\"), tr_dims, delimiter=\"\\n\", fmt=\"%-d\")\n",
    "    np.savetxt(os.path.join(save_path, f\"{save_name}_teLabelPoint{reveal_percent}.csv\"), te_points, delimiter=\"\\n\", fmt=\"%-d\")\n",
    "    np.savetxt(os.path.join(save_path, f\"{save_name}_teLabelDim{reveal_percent}.csv\"), te_dims, delimiter=\"\\n\", fmt=\"%-d\")\n",
    "\n",
    "def format_data(data_path, embeddings, save_path, save_name, seed=2):\n",
    "    tr_features, tr_labels, _, _, _ = data_utils.read_data(f'{data_path}/train.txt')\n",
    "    te_features, te_labels, _, _, _ = data_utils.read_data(f'{data_path}/test.txt')\n",
    "    label_features = format_label_embeddings(embeddings, f'{data_path}/Yf.txt')\n",
    "    \n",
    "    tr_filter_ixs = np.array((tr_labels.sum(axis=1)>5)&(tr_features.sum(axis=1)>0)).flatten()\n",
    "    tr_features = tr_features[tr_filter_ixs, :]\n",
    "    tr_labels = tr_labels[tr_filter_ixs, :]\n",
    "    \n",
    "    te_filter_ixs = np.array((te_labels.sum(axis=1)>5)&(te_features.sum(axis=1)>0)).flatten()\n",
    "    te_features = te_features[te_filter_ixs, :]\n",
    "    te_labels = te_labels[te_filter_ixs, :]\n",
    "    \n",
    "    _, tr_y_indeces_ax0, tr_y_indeces_ax1, tr_y_indeces = find(tr_labels, 0)\n",
    "    _, te_y_indeces_ax0, te_y_indeces_ax1, te_y_indeces = find(te_labels, 0)\n",
    "    \n",
    "    tr_x_values, tr_x_indeces_ax0, tr_x_indeces_ax1, _ = find(tr_features, 0, tr_filter_ixs)\n",
    "    te_x_values, te_x_indeces_ax0, te_x_indeces_ax1, _ = find(te_features, 0, te_filter_ixs)\n",
    "    \n",
    "    assert set(tr_x_indeces_ax0)==set(tr_y_indeces_ax0)\n",
    "    assert set(te_x_indeces_ax0)==set(te_y_indeces_ax0)\n",
    "    \n",
    "    np.savetxt(os.path.join(save_path, f\"{save_name}_trDataValue.csv\"), tr_x_values, delimiter=\"\\n\")\n",
    "    np.savetxt(os.path.join(save_path, f\"{save_name}_trDataPoint.csv\"), tr_x_indeces_ax0, delimiter=\"\\n\", fmt=\"%-d\")\n",
    "    np.savetxt(os.path.join(save_path, f\"{save_name}_trDataDim.csv\"), tr_x_indeces_ax1, delimiter=\"\\n\", fmt=\"%-d\")\n",
    "    np.savetxt(os.path.join(save_path, f\"{save_name}_teDataValue.csv\"), te_x_values, delimiter=\"\\n\")\n",
    "    np.savetxt(os.path.join(save_path, f\"{save_name}_teDataPoint.csv\"), te_x_indeces_ax0, delimiter=\"\\n\", fmt=\"%-d\")\n",
    "    np.savetxt(os.path.join(save_path, f\"{save_name}_teDataDim.csv\"), te_x_indeces_ax1, delimiter=\"\\n\", fmt=\"%-d\")\n",
    "    save_labels(tr_y_indeces_ax0, tr_y_indeces_ax1, te_y_indeces_ax0, te_y_indeces_ax1, save_path, save_name)\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    print(f\"TrC-{tr_y_indeces.shape[0]}\")\n",
    "    print(f\"TeC-{te_y_indeces.shape[0]}\")\n",
    "    for reveal_percent in [0.2, 0.4, 0.6, 0.8]: \n",
    "        tr_yr_indeces, tr_yh_indeces = train_test_split(tr_y_indeces, stratify=tr_y_indeces_ax0, test_size=1-reveal_percent)\n",
    "        tr_yr_indeces = pd.DataFrame(tr_yr_indeces).sort_values([0,1]).values\n",
    "        tr_yr_indeces_ax0 = tr_yr_indeces[:, 0]\n",
    "        tr_yr_indeces_ax1 = tr_yr_indeces[:, 1]\n",
    "#         tr_yh_indeces = pd.DataFrame(tr_yh_indeces).sort_values([0,1]).values\n",
    "#         tr_yh_indeces_ax0 = tr_yh_indeces[:, 0]\n",
    "#         tr_yh_indeces_ax1 = tr_yh_indeces[:, 1]\n",
    "        \n",
    "        te_yr_indeces, te_yh_indeces = train_test_split(te_y_indeces, stratify=te_y_indeces_ax0, test_size=1-reveal_percent)\n",
    "        te_yr_indeces = pd.DataFrame(te_yr_indeces).sort_values([0,1]).values\n",
    "        te_yr_indeces_ax0 = te_yr_indeces[:, 0]\n",
    "        te_yr_indeces_ax1 = te_yr_indeces[:, 1]\n",
    "#         te_yh_indeces = pd.DataFrame(te_yh_indeces).sort_values([0,1]).values\n",
    "#         te_yh_indeces_ax0 = te_yh_indeces[:, 0]\n",
    "#         te_yh_indeces_ax1 = te_yh_indeces[:, 1]\n",
    "        \n",
    "\n",
    "        print(f\"train {reveal_percent} count - {tr_yr_indeces_ax0.shape}\")\n",
    "        print(f\"test {reveal_percent} count - {te_yr_indeces_ax0.shape}\")\n",
    "        print(len(set(tr_yr_indeces_ax0)))\n",
    "        print(len(set(tr_y_indeces_ax0)))\n",
    "        assert set(tr_yr_indeces_ax0)==set(tr_y_indeces_ax0)\n",
    "        assert set(te_yr_indeces_ax0)==set(te_y_indeces_ax0)\n",
    "        save_labels(tr_yr_indeces_ax0, tr_yr_indeces_ax1, te_yr_indeces_ax0, te_yr_indeces_ax1, save_path, save_name, reveal_percent)\n",
    "#         save_labels(tr_yh_indeces_ax0, tr_yh_indeces_ax1, te_yh_indeces_ax0, te_yh_indeces_ax1, save_path, save_name, reveal_percent+1)\n",
    "    \n",
    "    lf_values, lf_indeces_ax0, lf_indeces_ax1, _ = find(label_features, None)\n",
    "    \n",
    "    np.savetxt(os.path.join(save_path, f\"{save_name}_LFValue.csv\"), lf_values, delimiter=\"\\n\")\n",
    "    np.savetxt(os.path.join(save_path, f\"{save_name}_LFPoint.csv\"), lf_indeces_ax0, delimiter=\"\\n\", fmt=\"%-d\")\n",
    "    np.savetxt(os.path.join(save_path, f\"{save_name}_LFDim.csv\"), lf_indeces_ax1, delimiter=\"\\n\", fmt=\"%-d\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec500 = KeyedVectors.load_word2vec_format(\"word2vec/enwiki_20180420_500d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13330\n",
      "#Words with no word embeddings 2873\n",
      "TrC-3074000\n",
      "TeC-816410\n",
      "train 0.2 count - (614800,)\n",
      "test 0.2 count - (163282,)\n",
      "329225\n",
      "329225\n",
      "train 0.4 count - (1229600,)\n",
      "test 0.4 count - (326564,)\n",
      "329225\n",
      "329225\n",
      "train 0.6 count - (1844400,)\n",
      "test 0.6 count - (489846,)\n",
      "329225\n",
      "329225\n",
      "train 0.8 count - (2459200,)\n",
      "test 0.8 count - (653128,)\n",
      "329225\n",
      "329225\n"
     ]
    }
   ],
   "source": [
    "format_data(\"AmazonCat-13K.bow\", word2vec500, \"formatted_data/amazonCat13/\", \"amz13\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_features, tr_labels, _, _, _ = data_utils.read_data(f'Wiki10/train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30938\n",
      "#Words with no word embeddings 8623\n"
     ]
    }
   ],
   "source": [
    "embeddings_dict = format_label_embeddings(word2vec500, \"Wiki10/Yf.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.12  , -0.0832, -0.5693, -0.4079,  0.0487,  0.3767,  0.1592,\n",
       "       -0.1209,  0.0719,  0.3957, -0.1751, -0.1508,  0.1907,  0.1112,\n",
       "       -0.435 ,  0.1184,  0.2914, -0.3504, -0.0166, -0.3228,  0.1756,\n",
       "        0.1289, -0.0596, -0.3531, -0.0995, -0.0564,  0.0473,  0.1466,\n",
       "       -0.2419,  0.0984,  0.0175, -0.2212,  0.39  , -0.1515, -0.1755,\n",
       "       -0.2398, -0.0321,  0.2368,  0.1169, -0.1467, -0.0715,  0.3322,\n",
       "        0.0921, -0.1857,  0.1427, -0.2311, -0.362 , -0.1397, -0.1115,\n",
       "       -0.0411, -0.4954, -0.1617,  0.1603,  0.1295, -0.1073, -0.1465,\n",
       "        0.0239,  0.0419,  0.2875, -0.0089, -0.0543,  0.2763, -0.2139,\n",
       "        0.1094,  0.2552,  0.2026, -0.2435,  0.3659, -0.345 ,  0.0467,\n",
       "       -0.1206,  0.1929,  0.2215, -0.0417,  0.013 ,  0.3128, -0.1731,\n",
       "       -0.1439, -0.2799,  0.0568,  0.0817,  0.03  ,  0.1544, -0.3517,\n",
       "        0.1678,  0.6397, -0.0846,  0.4675,  0.2243, -0.0734,  0.0351,\n",
       "       -0.3218,  0.6374, -0.2276,  0.022 ,  0.1767,  0.0961,  0.0982,\n",
       "        0.0184,  0.2443,  0.089 , -0.1334, -0.1626,  0.2669,  0.362 ,\n",
       "       -0.5693,  0.1241,  0.4652,  0.3748,  0.3521,  0.2617,  0.0905,\n",
       "       -0.6935, -0.0178,  0.2945,  0.1796,  0.3322,  0.2121, -0.0375,\n",
       "        0.3956, -0.217 , -0.3554, -0.0841,  0.2826,  0.1506,  0.2796,\n",
       "       -0.0711,  0.4676,  0.0979, -0.3678, -0.3166, -0.3543,  0.2349,\n",
       "        0.0048,  0.3225,  0.1503, -0.1311,  0.382 , -0.6272, -0.0133,\n",
       "        0.1201,  0.0451, -0.1597,  0.1731, -0.0849,  0.1016, -0.1885,\n",
       "       -0.1506,  0.0569, -0.3018,  0.2975,  0.3026,  0.164 , -0.2288,\n",
       "       -0.5057,  0.1982, -0.2153, -0.145 ,  0.2102,  0.6138, -0.0532,\n",
       "        0.0766, -0.4194, -0.3428,  0.4021,  0.0849, -0.0442,  0.103 ,\n",
       "        0.4473,  0.2539, -0.0397,  0.2183, -0.144 ,  0.2589, -0.3666,\n",
       "       -0.2708, -0.1601, -0.0933,  0.0335,  0.3422,  0.2048,  0.2009,\n",
       "       -0.2379, -0.4148,  0.0615, -0.3175, -0.2053,  0.0575,  0.6382,\n",
       "        0.1795, -0.5465,  0.3134, -0.0524,  0.0384,  0.2721, -0.1022,\n",
       "        0.2244,  0.1257, -0.2385,  0.0308, -0.0412,  0.0667,  0.0074,\n",
       "       -0.0718,  0.053 , -0.0241,  0.0716, -0.0096, -0.1757, -0.0066,\n",
       "        0.379 , -0.552 ,  0.123 ,  0.0523, -0.0487, -0.3463, -0.486 ,\n",
       "        0.082 ,  0.4271,  0.1047,  0.09  ,  0.1333, -0.0674,  0.4115,\n",
       "       -0.0198, -0.3318, -0.111 ,  0.2362, -0.0467, -0.1503, -0.6824,\n",
       "       -0.0297,  0.0011,  0.0117, -0.0051, -0.0843,  0.0011,  0.1767,\n",
       "       -0.3372, -0.3096,  0.1589, -0.4331, -0.0799,  0.0063, -0.3756,\n",
       "        0.3647,  0.2251, -0.2361,  0.2832,  0.1931, -0.4238,  0.1821,\n",
       "        0.0226,  0.3702, -0.4204,  0.1344,  0.0611, -0.5312,  0.0113,\n",
       "       -0.4423,  0.0183,  0.129 ,  0.1273,  0.0044, -0.1052,  0.5249,\n",
       "        0.0245, -0.0999,  0.1934, -0.1624, -0.0469,  0.134 ,  0.177 ,\n",
       "        0.4591,  0.204 , -0.0521,  0.3022, -0.0824,  0.411 ,  0.0137,\n",
       "       -0.5177,  0.6213,  0.2885,  0.0086,  0.3223,  0.2001,  0.0315,\n",
       "        0.1783,  0.4551,  0.3341,  0.2718, -0.2595, -0.0515,  0.4943,\n",
       "       -0.0417,  0.061 ,  0.3725,  0.4781,  0.1695,  0.0387, -0.0681,\n",
       "        0.1921,  0.0791, -0.1132,  0.0195,  0.1392, -0.0202,  0.1968,\n",
       "       -0.3192,  0.2591,  0.0114, -0.1785, -0.06  ,  0.4995, -0.2112,\n",
       "        0.1774,  0.1963,  0.2487, -0.1539,  0.0478, -0.0498, -0.2465,\n",
       "       -0.127 ,  0.251 , -0.1118,  0.2931,  0.2856,  0.0772, -0.2385,\n",
       "       -0.506 ,  0.0719, -0.1494, -0.7291,  0.3184, -0.0337,  0.0194,\n",
       "       -0.0076, -0.0829, -0.3282, -0.1198,  0.6491,  0.4628,  0.0566,\n",
       "        0.2599, -0.146 , -0.1596, -0.2906, -0.5058,  0.4143,  0.1018,\n",
       "       -0.3486, -0.1124,  0.1566, -0.1278, -0.0617, -0.0955, -0.0202,\n",
       "       -0.4387,  0.4454, -0.199 ,  0.1985, -0.0481,  0.114 ,  0.3221,\n",
       "       -0.1197,  0.1903, -0.0713,  0.2388,  0.0604, -0.3669, -0.1214,\n",
       "        0.0523, -0.3055,  0.4257, -0.0952,  0.1247,  0.3423, -0.1297,\n",
       "       -0.0787, -0.1513,  0.1454, -0.2143,  0.3117,  0.1186,  0.0872,\n",
       "       -0.5232,  0.1898,  0.1539, -0.5741,  0.0601, -0.0903, -0.1196,\n",
       "        0.1297, -0.145 , -0.0645,  0.1602,  0.4019, -0.0136,  0.0381,\n",
       "       -0.1903,  0.3555, -0.1172,  0.0102,  0.2761, -0.0969, -0.2103,\n",
       "        0.0046, -0.5019,  0.1923, -0.1208, -0.0671,  0.0218, -0.4948,\n",
       "        0.2927, -0.0293, -0.2276,  0.1641, -0.1425, -0.1417,  0.1151,\n",
       "       -0.0764,  0.3038,  0.0531, -0.2172, -0.4561, -0.0058,  0.4838,\n",
       "       -0.4797, -0.039 ,  0.0262,  0.1018, -0.1859, -0.2433,  0.1784,\n",
       "       -0.0453,  0.3451,  0.0431,  0.1765,  0.2871, -0.0312, -0.121 ,\n",
       "        0.0651,  0.3402, -0.2661, -0.0189, -0.1081,  0.1297, -0.0326,\n",
       "       -0.1617, -0.1363, -0.2164, -0.5155,  0.0193,  0.0461,  0.5682,\n",
       "        0.0472, -0.0522,  0.0432,  0.4759,  0.3313, -0.3952, -0.0438,\n",
       "       -0.303 ,  0.2203,  0.238 , -0.1292, -0.0989, -0.0153, -0.1056,\n",
       "        0.3573, -0.3321, -0.0715, -0.0797,  0.0181,  0.0707, -0.1669,\n",
       "       -0.1843, -0.2459,  0.0875, -0.2627,  0.028 , -0.3432,  0.0888,\n",
       "        0.0373, -0.2721,  0.0056, -0.1943,  0.3092, -0.1333, -0.1347,\n",
       "        0.266 , -0.0515,  0.3925, -0.1327, -0.0576, -0.1734,  0.2246,\n",
       "        0.2938,  0.171 ,  0.3162], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec500[\"dvd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.12      , -0.0832    , -0.5693    , -0.40790001,  0.0487    ,\n",
       "        0.37670001,  0.1592    , -0.1209    ,  0.0719    ,  0.39570001,\n",
       "       -0.1751    , -0.1508    ,  0.19069999,  0.1112    , -0.435     ,\n",
       "        0.1184    ,  0.29139999, -0.3504    , -0.0166    , -0.32280001,\n",
       "        0.17560001,  0.12890001, -0.0596    , -0.3531    , -0.0995    ,\n",
       "       -0.0564    ,  0.0473    ,  0.14659999, -0.2419    ,  0.0984    ,\n",
       "        0.0175    , -0.2212    ,  0.38999999, -0.1515    , -0.17550001,\n",
       "       -0.23980001, -0.0321    ,  0.2368    ,  0.1169    , -0.14669999,\n",
       "       -0.0715    ,  0.33219999,  0.0921    , -0.1857    ,  0.1427    ,\n",
       "       -0.23109999, -0.36199999, -0.1397    , -0.1115    , -0.0411    ,\n",
       "       -0.49540001, -0.1617    ,  0.1603    ,  0.1295    , -0.1073    ,\n",
       "       -0.14650001,  0.0239    ,  0.0419    ,  0.28749999, -0.0089    ,\n",
       "       -0.0543    ,  0.27630001, -0.2139    ,  0.1094    ,  0.2552    ,\n",
       "        0.2026    , -0.24349999,  0.36590001, -0.345     ,  0.0467    ,\n",
       "       -0.1206    ,  0.1929    ,  0.22149999, -0.0417    ,  0.013     ,\n",
       "        0.31279999, -0.17309999, -0.14390001, -0.27990001,  0.0568    ,\n",
       "        0.0817    ,  0.03      ,  0.15440001, -0.35170001,  0.16779999,\n",
       "        0.6397    , -0.0846    ,  0.4675    ,  0.2243    , -0.0734    ,\n",
       "        0.0351    , -0.32179999,  0.63739997, -0.22759999,  0.022     ,\n",
       "        0.1767    ,  0.0961    ,  0.0982    ,  0.0184    ,  0.24429999,\n",
       "        0.089     , -0.13339999, -0.1626    ,  0.2669    ,  0.36199999,\n",
       "       -0.5693    ,  0.1241    ,  0.46520001,  0.3748    ,  0.35210001,\n",
       "        0.2617    ,  0.0905    , -0.69349998, -0.0178    ,  0.29449999,\n",
       "        0.1796    ,  0.33219999,  0.2121    , -0.0375    ,  0.39559999,\n",
       "       -0.21699999, -0.3554    , -0.0841    ,  0.28259999,  0.1506    ,\n",
       "        0.27959999, -0.0711    ,  0.46759999,  0.0979    , -0.3678    ,\n",
       "       -0.31659999, -0.35429999,  0.2349    ,  0.0048    ,  0.32249999,\n",
       "        0.1503    , -0.1311    ,  0.382     , -0.62720001, -0.0133    ,\n",
       "        0.1201    ,  0.0451    , -0.15970001,  0.17309999, -0.0849    ,\n",
       "        0.1016    , -0.1885    , -0.1506    ,  0.0569    , -0.30180001,\n",
       "        0.29750001,  0.3026    ,  0.164     , -0.2288    , -0.50569999,\n",
       "        0.1982    , -0.21529999, -0.145     ,  0.2102    ,  0.61379999,\n",
       "       -0.0532    ,  0.0766    , -0.41940001, -0.34279999,  0.4021    ,\n",
       "        0.0849    , -0.0442    ,  0.103     ,  0.44729999,  0.25389999,\n",
       "       -0.0397    ,  0.2183    , -0.14399999,  0.25889999, -0.36660001,\n",
       "       -0.27079999, -0.1601    , -0.0933    ,  0.0335    ,  0.34220001,\n",
       "        0.20479999,  0.2009    , -0.2379    , -0.41479999,  0.0615    ,\n",
       "       -0.3175    , -0.2053    ,  0.0575    ,  0.63819999,  0.1795    ,\n",
       "       -0.54650003,  0.3134    , -0.0524    ,  0.0384    ,  0.2721    ,\n",
       "       -0.1022    ,  0.2244    ,  0.1257    , -0.2385    ,  0.0308    ,\n",
       "       -0.0412    ,  0.0667    ,  0.0074    , -0.0718    ,  0.053     ,\n",
       "       -0.0241    ,  0.0716    , -0.0096    , -0.17569999, -0.0066    ,\n",
       "        0.37900001, -0.55199999,  0.123     ,  0.0523    , -0.0487    ,\n",
       "       -0.34630001, -0.486     ,  0.082     ,  0.4271    ,  0.1047    ,\n",
       "        0.09      ,  0.13330001, -0.0674    ,  0.41150001, -0.0198    ,\n",
       "       -0.33180001, -0.111     ,  0.2362    , -0.0467    , -0.1503    ,\n",
       "       -0.68239999, -0.0297    ,  0.0011    ,  0.0117    , -0.0051    ,\n",
       "       -0.0843    ,  0.0011    ,  0.1767    , -0.33719999, -0.3096    ,\n",
       "        0.15889999, -0.43309999, -0.0799    ,  0.0063    , -0.37560001,\n",
       "        0.36469999,  0.2251    , -0.2361    ,  0.2832    ,  0.19310001,\n",
       "       -0.42379999,  0.1821    ,  0.0226    ,  0.37020001, -0.42039999,\n",
       "        0.1344    ,  0.0611    , -0.53119999,  0.0113    , -0.44229999,\n",
       "        0.0183    ,  0.12899999,  0.12729999,  0.0044    , -0.1052    ,\n",
       "        0.52490002,  0.0245    , -0.0999    ,  0.1934    , -0.16240001,\n",
       "       -0.0469    ,  0.134     ,  0.177     ,  0.45910001,  0.204     ,\n",
       "       -0.0521    ,  0.30219999, -0.0824    ,  0.41100001,  0.0137    ,\n",
       "       -0.51770002,  0.62129998,  0.28850001,  0.0086    ,  0.32229999,\n",
       "        0.2001    ,  0.0315    ,  0.17829999,  0.4551    ,  0.33410001,\n",
       "        0.27180001, -0.2595    , -0.0515    ,  0.49430001, -0.0417    ,\n",
       "        0.061     ,  0.3725    ,  0.4781    ,  0.16949999,  0.0387    ,\n",
       "       -0.0681    ,  0.1921    ,  0.0791    , -0.1132    ,  0.0195    ,\n",
       "        0.1392    , -0.0202    ,  0.19679999, -0.31920001,  0.25909999,\n",
       "        0.0114    , -0.1785    , -0.06      ,  0.49950001, -0.2112    ,\n",
       "        0.17739999,  0.1963    ,  0.24869999, -0.1539    ,  0.0478    ,\n",
       "       -0.0498    , -0.2465    , -0.127     ,  0.25099999, -0.1118    ,\n",
       "        0.2931    ,  0.28560001,  0.0772    , -0.2385    , -0.50599998,\n",
       "        0.0719    , -0.1494    , -0.72909999,  0.3184    , -0.0337    ,\n",
       "        0.0194    , -0.0076    , -0.0829    , -0.32820001, -0.1198    ,\n",
       "        0.64910001,  0.4628    ,  0.0566    ,  0.2599    , -0.146     ,\n",
       "       -0.1596    , -0.2906    , -0.50580001,  0.41429999,  0.1018    ,\n",
       "       -0.3486    , -0.1124    ,  0.1566    , -0.1278    , -0.0617    ,\n",
       "       -0.0955    , -0.0202    , -0.43869999,  0.4454    , -0.199     ,\n",
       "        0.19850001, -0.0481    ,  0.114     ,  0.32210001, -0.1197    ,\n",
       "        0.1903    , -0.0713    ,  0.2388    ,  0.0604    , -0.3669    ,\n",
       "       -0.1214    ,  0.0523    , -0.3055    ,  0.42570001, -0.0952    ,\n",
       "        0.1247    ,  0.3423    , -0.12970001, -0.0787    , -0.1513    ,\n",
       "        0.1454    , -0.21430001,  0.31169999,  0.1186    ,  0.0872    ,\n",
       "       -0.52319998,  0.18979999,  0.1539    , -0.57410002,  0.0601    ,\n",
       "       -0.0903    , -0.1196    ,  0.12970001, -0.145     , -0.0645    ,\n",
       "        0.1602    ,  0.40189999, -0.0136    ,  0.0381    , -0.1903    ,\n",
       "        0.35550001, -0.1172    ,  0.0102    ,  0.27610001, -0.0969    ,\n",
       "       -0.2103    ,  0.0046    , -0.50190002,  0.19230001, -0.1208    ,\n",
       "       -0.0671    ,  0.0218    , -0.4948    ,  0.29269999, -0.0293    ,\n",
       "       -0.22759999,  0.16410001, -0.1425    , -0.1417    ,  0.1151    ,\n",
       "       -0.0764    ,  0.30379999,  0.0531    , -0.2172    , -0.45609999,\n",
       "       -0.0058    ,  0.48379999, -0.4797    , -0.039     ,  0.0262    ,\n",
       "        0.1018    , -0.1859    , -0.24330001,  0.17839999, -0.0453    ,\n",
       "        0.34509999,  0.0431    ,  0.17649999,  0.28709999, -0.0312    ,\n",
       "       -0.121     ,  0.0651    ,  0.34020001, -0.26609999, -0.0189    ,\n",
       "       -0.1081    ,  0.12970001, -0.0326    , -0.1617    , -0.1363    ,\n",
       "       -0.2164    , -0.51550001,  0.0193    ,  0.0461    ,  0.56819999,\n",
       "        0.0472    , -0.0522    ,  0.0432    ,  0.47589999,  0.33129999,\n",
       "       -0.39520001, -0.0438    , -0.303     ,  0.2203    ,  0.23800001,\n",
       "       -0.1292    , -0.0989    , -0.0153    , -0.1056    ,  0.35730001,\n",
       "       -0.3321    , -0.0715    , -0.0797    ,  0.0181    ,  0.0707    ,\n",
       "       -0.16689999, -0.18430001, -0.24590001,  0.0875    , -0.26269999,\n",
       "        0.028     , -0.3432    ,  0.0888    ,  0.0373    , -0.2721    ,\n",
       "        0.0056    , -0.1943    ,  0.30919999, -0.13330001, -0.1347    ,\n",
       "        0.266     , -0.0515    ,  0.39250001, -0.1327    , -0.0576    ,\n",
       "       -0.1734    ,  0.2246    ,  0.2938    ,  0.171     ,  0.31619999])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dict[9998]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
